//
//  RNSpeech.m
//  chatapp
//
//  Created by songdewei on 2023/4/9.
//

#import "RNSpeech.h"

@implementation RNSpeech

- (instancetype)init {
    if (self = [super init]) {
        NSLocale *locale = [NSLocale localeWithLocaleIdentifier:@"zh-CN"];
        self.speechRecognizer = [[SFSpeechRecognizer alloc] initWithLocale:locale];
        self.audioEngine = [[AVAudioEngine alloc] init];
    }

    return self;
}

RCT_EXPORT_MODULE(RNSpeech)


RCT_EXPORT_METHOD(requestAuthorization:(RCTResponseSenderBlock)callback) {
    // 请求权限
    [SFSpeechRecognizer requestAuthorization:^(SFSpeechRecognizerAuthorizationStatus status) {
        if (status == SFSpeechRecognizerAuthorizationStatusAuthorized) {
            if(callback){
                callback(@[[NSNull null]]);
            }
        } else {
            [self sendEventWithName:@"onError"
                               body:[NSString stringWithFormat:@"权限请求失败(%ld)", (long)status]];
            if(callback){
                callback(@[[NSString stringWithFormat:@"权限请求失败(%ld)", (long)status]]);
            }
        }
    }];
}

RCT_EXPORT_METHOD(startRecord) {
    NSError *error = nil;
    AVAudioSession *audioSession = [AVAudioSession sharedInstance];

    [audioSession setCategory:AVAudioSessionCategoryRecord mode:AVAudioSessionModeMeasurement options:AVAudioSessionCategoryOptionDuckOthers error:&error];
    [audioSession setActive:YES withOptions:AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation error:&error];

    if (self.recognitionRequest) {
        [self.recognitionRequest endAudio];
    }

    self.recognitionRequest = [[SFSpeechAudioBufferRecognitionRequest alloc] init];
    self.recognitionRequest.shouldReportPartialResults = YES;

    AVAudioFormat *recordingFormat = [[self.audioEngine inputNode] outputFormatForBus:0];
    [[self.audioEngine inputNode] installTapOnBus:0
                                       bufferSize:1024
                                           format:recordingFormat
                                            block:^(AVAudioPCMBuffer *_Nonnull buffer, AVAudioTime *_Nonnull when) {
        [self.recognitionRequest appendAudioPCMBuffer:buffer];
    }];


    [self.audioEngine prepare];
    [self.audioEngine startAndReturnError:&error];

    if (error) {
        [self sendEventWithName:@"onError"
                           body:@{
             @"code": @([error code]),
             @"message": [error localizedDescription]
        }];
    }
}

RCT_EXPORT_METHOD(stopRecord:(RCTResponseSenderBlock)callback) {
    [[self.audioEngine inputNode] removeTapOnBus:0];
    [self.audioEngine stop];
    [self.recognitionRequest endAudio];

    [self.speechRecognizer recognitionTaskWithRequest:self.recognitionRequest
                                        resultHandler:^(SFSpeechRecognitionResult *_Nullable result, NSError *_Nullable error) {
        NSLog(@"is final: %d  result: %@", result.isFinal, result.bestTranscription.formattedString);

        if (error) {
            [self sendEventWithName:@"onError"
                               body:@{
                 @"code": @([error code]),
                 @"message": [error localizedDescription]
            }];
        }

        if (result.isFinal) {
            NSString *text = result.bestTranscription.formattedString;
            [self sendEventWithName:@"onSuccess"
                               body:text];
            if(callback){
                callback(@[text]);
            }
        }
    }];
}


+ (BOOL)requiresMainQueueSetup {
    return YES;
}

- (NSArray<NSString *> *)supportedEvents {
    return @[@"onSuccess", @"onError"];
}

- (void)startObserving {
}

- (void)stopObserving {
}

@end
